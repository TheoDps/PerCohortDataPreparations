/*
 * --------------------------------------------------------
 *  eQTLGen/PerCohortPreparations Nextflow base config file
 * --------------------------------------------------------
 * A 'blank slate' config file, appropriate for general
 * use on most high performace compute environments.
 * Assumes that all software is installed and available
 * on the PATH. Runs in `local` mode - all jobs will be
 * run on the logged in environment.
 */

process {

  // TODO nf-core: Check the defaults for all processes
  // cpus = { check_max( 1 * task.attempt, 'cpus' ) }
  // memory = { check_max( 7.GB * task.attempt, 'memory' ) }
  // time = { check_max( 4.h * task.attempt, 'time' ) }

  errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
  maxRetries = 1
  maxErrors = '-1'

  // Process-specific resource requirements
  // NOTE - Only one of the labels below are used in the fastqc process in the main script.
  //        If possible, it would be nice to keep the same label naming convention when
  //        adding in your processes.
  // TODO nf-core: Customise requirements for specific processes.
  // See https://www.nextflow.io/docs/latest/config.html#config-process-selectors
  withLabel:process_low {
    cpus = { check_max( 2 * task.attempt, 'cpus' ) }
    // memory = { check_max( 14.GB * task.attempt, 'memory' ) }
    time = { check_max( 6.h * task.attempt, 'time' ) }
  }
  withLabel:process_medium {
    cpus = { check_max( 6 * task.attempt, 'cpus' ) }
    // memory = { check_max( 42.GB * task.attempt, 'memory' ) }
    time = { check_max( 8.h * task.attempt, 'time' ) }
  }
  withLabel:process_high {
    cpus = { check_max( 12 * task.attempt, 'cpus' ) }
    // memory = { check_max( 84.GB * task.attempt, 'memory' ) }
    time = { check_max( 10.h * task.attempt, 'time' ) }
  }
  withLabel:process_long {
    time = { check_max( 20.h * task.attempt, 'time' ) }
  }

  withName: ParseCohortName {
    // memory = { check_max( 1.GB * task.attempt, 'memory' ) }
    // cpus = 1
    // time = { check_max( 1.m * task.attempt, 'time' ) }
    clusterOptions = '-N ParseCohortName -pe smp 1 -adds l_hard h_vmem 1G -adds l_hard m_mem_free 1G -jc short -adds l_hard hostname "c*"'
  }

  withName: CreateMapperFiles {
    // memory = { check_max( 30.GB * task.attempt, 'memory' ) }
    // cpus = 1
    // time = { check_max( 12.h * task.attempt, 'time' ) }
    clusterOptions = '-N CreateMapperFiles -pe smp 1 -adds l_hard h_vmem 30G -adds l_hard m_mem_free 30G -jc long -adds l_hard hostname "c*"'
  }

  withName: EncodeData {
    // memory = { check_max( 50.GB * task.attempt, 'memory' ) }
    // cpus = 1
    // time = { check_max( 5.h * task.attempt, 'time' ) }
    // Reduced memory requirement to 40G as 50G sends jobs to qw state
    clusterOptions = '-N EncodeData -pe smp 1 -adds l_hard h_vmem 40G -adds l_hard m_mem_free 40G -jc short -adds l_hard hostname "c*"'
  }

  withName: PartialDerivatives {
    // memory = { check_max( 30.GB * task.attempt, 'memory' ) }
    // cpus = 1
    // time = { check_max( 5.h * task.attempt, 'time' ) }
    clusterOptions = '-N PartialDerivatives -pe smp 1 -adds l_hard h_vmem 30G -adds l_hard m_mem_free 30G -jc short -adds l_hard hostname "c*"'
  }

  withName: PermuteData {
    // memory = { check_max( 10.GB * task.attempt, 'memory' ) }
    // cpus = 8
    // time = { check_max( 5.m * task.attempt, 'time' ) }
    clusterOptions = '-N PermuteData -pe smp 8 -adds l_hard h_vmem 10G -adds l_hard m_mem_free 10G -jc short -adds l_hard hostname "c*"'
  }

  withName: EncodeDataPermuted {
    // memory = { check_max( 50.GB * task.attempt, 'memory' ) }
    // cpus = 1
    // time = { check_max( 5.h * task.attempt, 'time' ) }
    // Reduced memory requirement to 40G as 50G sends jobs to qw state
    clusterOptions = '-N EncodeDataPermuted -pe smp 1 -adds l_hard h_vmem 40G -adds l_hard m_mem_free 40G -jc short -adds l_hard hostname "c*"'
  }

  withName: PartialDerivativesPermuted {
    // memory = { check_max( 40.GB * task.attempt, 'memory' ) }
    // cpus = 1
    // time = { check_max( 5.h * task.attempt, 'time' ) }
    clusterOptions = '-N PartialDerivativesPermuted -pe smp 1 -adds l_hard h_vmem 40G -adds l_hard m_mem_free 40G -jc short -adds l_hard hostname "c*"'
  }

  withName: PrepareGenRegPcs {
    // memory = { check_max( 10.GB * task.attempt, 'memory' ) }
    // cpus = 1
    // time = { check_max( 10.m * task.attempt, 'time' ) }
    clusterOptions = '-N PrepareGenRegPcs -pe smp 1 -adds l_hard h_vmem 10G -adds l_hard m_mem_free 10G -jc short -adds l_hard hostname "c*"'
  }

  withName: RunGenRegPcs {
    // memory = { check_max( 20.GB * task.attempt, 'memory' ) }
    // cpus = 1
    // time = { check_max( 3.h * task.attempt, 'time' ) }
    clusterOptions = '-N RunGenRegPcs -pe smp 1 -adds l_hard h_vmem 20G -adds l_hard m_mem_free 20G -jc short -adds l_hard hostname "c*"'
  }

  withName: OrganizeEncodedData {
    // memory = { check_max( 2.GB * task.attempt, 'memory' ) }
    // cpus = 1
    // time = { check_max( 30.m * task.attempt, 'time' ) }
    clusterOptions = '-N OrganizeEncodedData -pe smp 1 -adds l_hard h_vmem 2G -adds l_hard m_mem_free 2G -jc short -adds l_hard hostname "c*"'
  }

  withName: ReplaceSampleNames {
    // memory = { check_max( 10.GB * task.attempt, 'memory' ) }
    // cpus = 1
    // time = { check_max( 30.m * task.attempt, 'time' ) }
    clusterOptions = '-N ReplaceSampleNames -pe smp 1 -adds l_hard h_vmem 10G -adds l_hard m_mem_free 10G -jc short -adds l_hard hostname "c*"'
  }
}
